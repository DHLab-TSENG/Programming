---
title: "4. Data Preprocessing"
author: "Yi-Ju Tseng"
format:
  revealjs:
    slide-number: c/t
    show-slide-number: all
editor: visual
---

## 資料分析步驟

-   資料匯入
-   **資料清洗處理**
-   資料分析
-   資料呈現與視覺化

## 資料清洗與處理

-   Tidy Data
-   子集Subset
-   資料型態轉換處理
-   文字字串處理
-   資料組合
-   長寬表轉換
-   遺漏值處理

## 前置作業

為了成功從https (加密封包傳輸)下載資料，首先取消證書驗證

```{python}
#| echo: true
import ssl
ssl._create_default_https_context = ssl._create_unverified_context
```

## Tidy Data

Each column is a variable. Each row is an observation.

-   一個欄位（Column）內只有一個數值，最好要有凡人看得懂的Column Name
-   不同的觀察值應該要在不同列（Row）
-   一張表裡面，有所有分析需要的資料
-   如果一定要多張表，中間一定要有index可以把表串起來
-   One file, one table

## 資料清洗與處理

-   Tidy Data
-   **子集Subset**
-   資料型態轉換處理
-   文字字串處理
-   資料組合
-   長寬表轉換
-   遺漏值處理

# 子集Subset

## 子集Subset - 一維資料

之前有介紹使用`[ ]`取出單一或多個元素的方法，可應用於：

-   list: `[a,b,c,...]`, list\[`index`\]
-   dist: `{key1:value1, key2:value2,...}`, dist\[`key`\]

```{python}
#| echo: true
list1 = ["Tom","Ryan","Mark"]
list1[1] ##取出list的第二個元素
```

```{python}
#| echo: true
dist1 = {"Name":"Tom","Age":20,"Parents":"Mark"}
dist1["Name"] ##取出dist中key為Name的value
```

## 子集Subset - 一維資料

也可以用“負號”表示反向的順序，-1為最後一個值

```{python}
#| echo: true
print(list1)
print(list1[-1])
```

## 子集Subset - 二維資料head()

若想要快速取得資料框的前幾列(Row)或後幾列，也可使用`.head()`和`.tail()`函數

```{python}
#| echo: true
import pandas as pd
df1 = pd.DataFrame({"ID":[1, 2, 3, 4],
                    "Name":["Tom","Emma","Ryan","Amy"]})
```

::: columns
::: column
```{python}
#| echo: true
df1
```
:::

::: column
```{python}
#| echo: true
df1.head(2)
```
:::
:::

## 子集Subset - 二維資料tail()

若想要快速取得資料框的前幾列(Row)或後幾列，也可使用`.head()`和`.tail()`函數

::: columns
::: column
```{python}
#| echo: true
df1
```
:::

::: column
```{python}
#| echo: true
df1.tail(2)
```
:::
:::

## 子集Subset - 二維資料 取值 (column)

::: columns
::: column
資料框物件名稱`[`欄位名稱`]`：取出sequence

```{python}
#| echo: true
df1["Name"]
```
:::

::: column
資料框物件名稱`[[`欄位名稱`]]`：取出資料框

```{python}
#| echo: true
df1[["Name"]]
```
:::
:::

## 子集Subset - 二維資料 取值 (row)

資料框物件名稱`[`row slice`]`

::: columns
::: column
```{python}
#| echo: true
df1
```
:::

::: column
```{python}
#| echo: true
df1[0:2]
```
:::
:::

## 子集Subset - Recap

-   一維資料
    -   list: `[a,b,c,...]`, list\[`index`\]
    -   dist: `{key1:value1, key2:value2,...}`, dist\[`key`\]
-   二維資料
    -   column: 資料框物件`[`欄位名稱`]`：取出sequence
    -   column: 資料框物件`[[`欄位名稱`]]`：取出資料框
    -   row: 資料框物件`[`row slice`]` (ex. 資料框物件`[2:10]`)
    -   row: 資料框物件`.head()`, 資料框物件`.tail()`函數

## 資料清洗與處理

-   Tidy Data
-   子集Subset
-   **資料型態轉換處理**
-   文字字串處理
-   資料組合
-   長寬表轉換
-   遺漏值處理

# 資料型態轉換處理

## 資料型態轉換處理

包括**資料型態檢查**與**資料型態轉換**

Data Types 資料型態

-   **文字 (text, string, character)**
-   **數值 (numeric)**
-   **布林變數 (Boolean, logic)**
-   **日期 (date)**

## Check Data Type

使用`type()`函數可查看資料結構

```{python}
#| echo: true
import pandas as pd
df1 = pd.DataFrame({"ID":[1, 2, 3, 4],
                    "Name":["Tom","Emma","Ryan","Amy"]})
type(df1)
```

```{python}
#| echo: true
dist1 = {"id":1, "name":"Ryan", "School":"CGU"}
type(dist1)
```

## 資料型態檢查 - isinstance

使用`isinstance()`函數檢查資料型態，回傳布林變數，若為**真**，回傳**TRUE**

-   是否為**數字** `isinstance(變數名稱,(int,float))`
-   是否為**文字** `isinstance(變數名稱,str)`
-   是否為**布林變數** `isinstance(變數名稱,bool)`

```{python}
#| echo: true
num = 100
isinstance(num,int)
```

```{python}
#| echo: true
isinstance(num,float)
```

## 資料型態檢查 - isinstance

使用`isinstance()`函數檢查資料型態，回傳布林變數，若為**真**，回傳**TRUE**

-   是否為**數字** `isinstance(變數名稱,(int,float))`
-   是否為**文字** `isinstance(變數名稱,str)`
-   是否為**布林變數** `isinstance(變數名稱,bool)`

```{python}
#| echo: true
isinstance(num,(int,float))
```

```{python}
#| echo: true
text = "100"
isinstance(text,(int,float))
```

```{python}
#| echo: true
text = "100"
isinstance(text,str)
```

## 資料型態轉換 - 複習Python 101

使用`int()`, `float()`, `str()`函數轉換型態

-   轉換為**整數** `int(變數名稱)`
-   轉換為**浮點數** `float(變數名稱)`
-   轉換為**文字** `str(變數名稱)`

```{python}
#| echo: true
cha = "100"
cha_int = int(cha)
type(cha_int)
```

## 資料型態轉換

若無法順利完成轉換，會出現錯誤訊息

```{python}
#| eval: false
#| echo: true
int("abc")
```

## 資料型態轉換處理 - Recap

::: columns
::: column
**資料型態檢查**

-   `type()`查看資料結構
-   **數字** `isinstance(變數,(int,float))`
-   **文字** `isinstance(變數,str)`
-   **布林變數** `isinstance(變數,bool)`
:::

::: column
**資料型態轉換**

-   轉換為**整數** `int(變數)`
-   轉換為**浮點數** `float(變數)`
-   轉換為**文字** `str(變數)`
:::
:::

## Hands-on 資料型態轉換練習

回想起台積電的資料

```{python}
#| echo: true
import requests
from bs4 import BeautifulSoup
StockUrl = "https://tw.stock.yahoo.com/quote/2330"
res = requests.get(StockUrl)
soup = BeautifulSoup(res.text, "html.parser")
price_type = soup.select(".price-detail-item .C\(\#232a31\)")
price_detail = soup.select(".price-detail-item .Fw\(600\)")
type_list=[]
price_list=[]
for i in price_type:
  type_list.append(i.get_text())
for i in price_detail:
  price_list.append(i.get_text())
import pandas as pd
price_df = pd.DataFrame({"Type" : type_list, "Price":price_list})
```

## Hands-on 資料型態轉換練習

回想起台積電的資料

```{python}
price_df
```

## Hands-on 資料型態轉換練習

-   Price欄位的資料型態是？
-   如何將Price欄位轉換成數字？
-   **Hint**: 先做該欄位第一個數字，以此類推

## 資料清洗與處理

-   Tidy Data
-   子集Subset
-   資料型態轉換處理
-   **文字字串處理**
-   資料組合
-   長寬表轉換
-   遺漏值處理

# 文字字串處理

## 文字字串處理

-   基本查詢
-   基本處理
-   搜尋字串

## 基本查詢

-   字串長度 `len(變數名稱)`
-   字串內包含某字的個數 `.count(某字)`

```{python}
#| echo: true
str_ex = "Hello World"
len(str_ex)
```

```{python}
#| echo: true
str_ex.count("o")
```

## 基本處理

-   切割 `字串變數.split()` **Split**
-   子集 `字串變數[:]` **sub string**, **Slice**
-   大小寫轉換 `字串變數.upper()` `字串變數.lower()`
-   兩文字連接 `+` `字串變數.join(字串清單list)`
-   文字取代 `字串變數.replace(舊值,新值)` **substitute**
-   前後空白去除 `字串變數.strip(字元,預設空白)` **trim**

## 基本處理-切割

`字串變數.split(用什麼符號切割)`

```{python}
#| echo: true
str_ex = "Hello World"
str_ex.split(" ")
```

## 基本處理-子集（切一小段）

`字串變數[開始位置:結束位置]`（不包含結束位置）

```{python}
#| echo: true
str_ex
```

```{python}
#| echo: true
str_ex[1:5]
```

## 基本處理-大小寫轉換

-   `字串變數.upper()`
-   `字串變數.lower()`

```{python}
#| echo: true
str_ex.upper()
```

```{python}
#| echo: true
str_ex.lower()
```

## 基本處理-兩文字連接

-   字串1`+`字串2

```{python}
#| echo: true
"Hello" + "World"
```

-   `字串變數.join(字串清單list)`，字串變數為字串間隔

```{python}
#| echo: true
str_list = ["桃園市","龜山區","文化一路"]
space = " "
space.join(str_list)
```

## 基本處理-文字取代

`字串變數.replace(舊值,新值)` **substitute**

```{python}
#| echo: true
print(str_ex)
str_ex.replace("o","0")
```

## 基本處理-前後空白去除

`字串變數.strip(字元,預設空白)` **trim**

```{python}
#| echo: true
space_ex = "    CGU.   "
space_ex.strip()
```

```{python}
#| echo: true
dot_ex = "CGU."
dot_ex.strip(".")
```

## 基本處理 - Recap

-   切割 `字串變數.split()` **Split**
-   子集 `字串變數[:]` **sub string**, **Slice**
-   大小寫轉換 `字串變數.upper()` `字串變數.lower()`
-   兩文字連接 `+` `字串變數.join(字串清單list)`
-   文字取代 `字串變數.replace(舊值,新值)` **substitute**
-   前後空白去除 `字串變數.strip(字元,預設空白)` **trim**

## Hands-on 字串基本處理

回想起台積電的資料

```{python}
#| echo: true
import requests
from bs4 import BeautifulSoup
StockUrl = "https://tw.stock.yahoo.com/quote/2330"
res = requests.get(StockUrl)
soup = BeautifulSoup(res.text, "html.parser")
price_type = soup.select(".price-detail-item .C\(\#232a31\)")
price_detail = soup.select(".price-detail-item .Fw\(600\)")
type_list=[]
price_list=[]
for i in price_type:
  type_list.append(i.get_text())
for i in price_detail:
  price_list.append(i.get_text())
import pandas as pd
price_df = pd.DataFrame({"Type" : type_list, "Price":price_list})
```

## Hands-on 字串基本處理

回想起台積電的資料

```{python}
price_df
```

## Hands-on 字串基本處理

-   請把Price欄位中的`%`符號移除，並在相對應的Type欄位加上%符號
-   請把Price欄位中的`,`移除，再將整個Price欄位轉為數字

## 搜尋字串

-   使用`==`, `in`完整比對
-   **有分大小寫**

```{python}
#| echo: true
str1="CGU"
str2="cgu"
str3="CGU"
str1 == str2
```

```{python}
#| echo: true
str1 == str3
```

```{python}
#| echo: true
str1 in ["CGUST","NTU","NYCU"]
```

```{python}
#| echo: true
str1 in ["CGUST","CGU","NYCU"]
```

## 搜尋字串 - 是否包含某字

-   `字串變數.find(搜尋字串)`，回傳index，回傳-1表示沒有
-   `字串變數.count(計算字串)`，回傳個數

```{python}
#| echo: true
str1
```

```{python}
#| echo: true
str1.find("C")
```

```{python}
#| echo: true
str2
```

```{python}
#| echo: true
str2.find("C")
```

```{python}
#| echo: true
str2.count("C")
```

## 搜尋字串 - re套件

使用正規表示式搜尋文字，需載入`re`套件(不用安裝)

-   `re.match("找尋目標","在哪找")`找字串是否為找尋目標開頭
-   `re.search("找尋目標","在哪找")`找字串是否包含為找尋目標

```{python}
#| echo: true
import re
re.match("A","Alex")
```

```{python}
#| echo: true
re.match("l","Alex")
print(re.match("l","Alex"))
```

```{python}
#| echo: true
re.search("l","Alex")
```

## 搜尋字串 - 基本正規表示式

-   `re.search("找尋目標","在哪找")`，`"找尋目標"`可以是正規表示式
    -   `^`開頭
    -   `$`結尾

```{python}
#| echo: true
re.search("^l","Alex")
print(re.search("^l","Alex"))
```

```{python}
#| echo: true
re.search("x$","Alex")
```

## 搜尋字串 - 從list中搜尋

-   r = `re.compile("找尋目標")`，`"找尋目標"`可以是正規表示式
-   `filter(r.search,想找的list)`

```{python}
#| echo: true
mylist = ["dog", "cat", "wildcat", "thundercat", "cow", "hooo","catxx"]
r = re.compile("cat")
newlist = list(filter(r.search, mylist)) 
print(newlist)
```

## 搜尋字串 - 基本正規表示式

-   `*`0-n個
-   `+`1-n個
-   `[]`包含某些字
-   `d`包含0-9...
-   [參考資料](https://selflearningsuccess.com/python-regex/#%E5%90%84%E7%A8%AE%E5%B9%AB%E5%8A%A9%E4%BD%A0%E6%AF%94%E5%B0%8D%E7%9A%84%E5%B7%A5%E5%85%B7)

```{python}
#| echo: true
re.search("[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]+","yjtseng@nycu.edu.tw")
```

## 搜尋字串 - Recap

-   使用`==`, `in`完整比對
-   `re.match("找尋目標","在哪找")`
-   `re.search("找尋目標","在哪找")`
-   "在哪找"如果是list
    -   r = `re.compile("找尋目標")`
    -   `filter(r.search,想找的list)`
-   "找尋目標"可以是正規表示式
    -   `^`開頭, `$`結尾

## Hands-on 搜尋字串

回想台北市腳踏車資料

-   練習用資料：[YouBike2.0臺北市公共自行車即時資訊](https://data.gov.tw/dataset/137993)
-   API地址[在此](https://tcgbusfs.blob.core.windows.net/dotapp/youbike/v2/youbike_immediate.json)
-   將資料匯入Python中
-   找到資料的儲存處

```{python}
#| echo: true
#| eval: false
import requests, json
# step 1 requests.get
res = requests.get("https://tcgbusfs.blob.core.windows.net/dotapp/youbike/v2/youbike_immediate.json")
# step 2 conver to json
bike_data = res.json()
# step 3 conver to dataframe
bike_df = pd.DataFrame(bike_data)
print(bike_df)
```

## Hands-on 搜尋字串

```{python}
#| echo: true
import requests, json
# step 1 requests.get
res = requests.get("https://tcgbusfs.blob.core.windows.net/dotapp/youbike/v2/youbike_immediate.json")
# step 2 conver to json
bike_data = res.json()
# step 3 conver to dataframe
bike_df = pd.DataFrame(bike_data)
print(bike_df)
```

## Hands-on 搜尋字串

-   匯入台北市腳踏車資料 (詳見上面幾頁)
-   找到所有“國小”的站點

## 資料清洗與處理

-   Tidy Data
-   子集Subset
-   資料型態轉換處理
-   文字字串處理
-   **資料組合**
-   長寬表轉換
-   遺漏值處理

# 資料組合

## 資料組合

有時需要在資料框新增一列，或新增一行

-   Row 的組合 `pd`.`concat([df1, df2])`
-   Column 的組合 `pd`.`concat([df1, df2],axis=1)`

## 資料組合 - .concat()

`pd`.`concat([pd物件1, pd物件2])`，預設為row方向的合併

```{python}
#| echo: true
df1 = pd.DataFrame({"ID":[1, 2, 3, 4],
                    "Name":["Tom","Emma","Ryan","Amy"]})
df2 = pd.DataFrame({"ID":[5,6,7],
                    "Name":["A","B","C"]})                 
newdf = pd.concat([df1,df2])
print(newdf)
```

## 資料組合 - .concat()

`pd`.`concat([pd物件1, pd物件2],axis=1)`，利用`axis=1`改為column方向的合併

```{python}
#| echo: true
df1 = pd.DataFrame({"ID":[1, 2, 3, 4],
                    "Name":["Tom","Emma","Ryan","Amy"]})
df2 = pd.DataFrame({"School":["NYCU","CGU","NTU"],
                    "Score":[60,70,80]})                 
newdf = pd.concat([df1,df2],axis=1)
print(newdf)
```

## 資料組合 - Recap

有時需要在資料框新增一列，或新增一行

-   Row 的組合 `pd`.`concat([df1, df2])`
-   Column 的組合 `pd`.`concat([df1, df2],axis=1)`

# 資料結合 (Join in SQL)

## 資料結合 (Join in SQL)

除了按照行列順序的組合外，更常有的情形是依照某個欄位的值作為結合依據，如：

-   用學號把以下兩個資料框結合成一個資料框
    -   學號與姓名資料框
    -   學號與宿舍床位資料框
-   用縣市名稱與年度將人口資料與醫療資源資料結合

## 資料結合 (Join in SQL)

可以用`pd`.`merge()`函數將資料框結合，使用方法為`merge(資料框left,資料框right,how="["left","right","inner","outer"],on="結合依據欄位")`

```{python}
#| echo: true
nameDF=pd.DataFrame({"ID":[1,2,3,4,5],
                  "Name":["Amy","Bob","Chris","David","Emma"]})
scoreDF=pd.DataFrame({"ID":[1,2,4],
                  "Score":[60,90,50]})
```

## 資料結合 (Join in SQL)

資料範例

::: columns
::: column
```{python}
#| echo: true
print(nameDF)
```
:::

::: column
```{python}
#| echo: true
print(scoreDF)
```
:::
:::

## 資料結合 (Join in SQL)

`merge(資料框left,資料框right,how="["left","right","inner","outer"],on="結合依據欄位")`

How:

-   inner：保留有對應到的資料
-   left：保留左邊資料框的所有資料
-   right：保留右邊資料框的所有資料
-   outer：保留所有資料

## 資料結合 (Join) - inner

::: columns
::: column
```{python}
#| echo: true
print(nameDF)
```
:::

::: column
```{python}
#| echo: true
print(scoreDF)
```
:::
:::

inner join - 預設:`merge(資料框left,資料框right,how="inner",on="結合欄位")`

```{python}
#| echo: true
pd.merge(nameDF,scoreDF)
```

## 資料結合 (Join) - outer

::: columns
::: column
```{python}
#| echo: true
print(nameDF)
```
:::

::: column
```{python}
#| echo: true
print(scoreDF)
```
:::
:::

outer join: `merge(資料框left,資料框right,how="outer",on="結合欄位")`

```{python}
#| echo: true
pd.merge(nameDF,scoreDF,how="outer",on="ID")
```

## 資料結合 (Join) - left

::: columns
::: column
```{python}
#| echo: true
print(nameDF)
```
:::

::: column
```{python}
#| echo: true
print(scoreDF)
```
:::
:::

left join: `merge(資料框left,資料框right,how="left",on="結合欄位")`

```{python}
#| echo: true
pd.merge(nameDF,scoreDF,how="left",on="ID")
```

## 資料結合 (Join) - Recap

`merge(資料框left,資料框right,how="["left","right","inner","outer"],on="結合依據欄位")`

How:

-   inner：保留有對應到的資料
-   left：保留左邊資料框的所有資料
-   right：保留右邊資料框的所有資料
-   outer：保留所有資料

## Hands-on 資料結合練習

-   下載或直接載入[COVID-19案例數資料](https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv)
-   下載或直接載入[COVID-19死亡數資料](https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv)
-   分別讀入兩個csv檔
-   依照Province/State,Country/Region,Lat,Long四個欄位，將兩張表格結合，**只留下有對應到的資料**
-   請問結合後的資料有幾列？

## 資料清洗與處理

-   Tidy Data
-   子集Subset
-   資料型態轉換處理
-   文字字串處理
-   資料組合
-   **長寬表轉換**
-   遺漏值處理

# 長表與寬表

## 長表與寬表

-   在資料處理的過程中，常因各種需求，需要執行長寬表互換的動作
-   `pandas` 套件提供完整的轉換功能
-   `pd`.`pivot()`

## 長表轉寬表

以下是一個長表的範例

```{python}
#| echo: true
raw_data = {'patient': [1, 1, 1, 2, 2],
                'obs': [1, 2, 3, 1, 2],
              'score': [6252, 24243, 2345, 2342, 23525]}

df = pd.DataFrame(raw_data)
df
```

## 長表轉寬表 資料框.pivot()

-   `df`資料框中，共有patient, obs, score等四個欄位 (Column)，屬於長表
-   `資料框.pivot(index=識別欄位, columns=轉寬表欄位名稱, values=轉寬表欄位內容)`
-   以`patient`為基準，obs欄位的值轉換為新欄位，並將score欄位填入

## 長表轉寬表 資料框.pivot()

```{python}
#| echo: true
df_wide=df.pivot(index='patient', columns='obs', values='score')
df_wide
```

## 寬表轉長表 pd.melt()

寬表範例

```{python}
#| echo: true
df = pd.DataFrame({'team': ['A', 'B', 'C', 'D'],
                   'points': [88, 91, 99, 94],
                   'assists': [12, 17, 24, 28],
                   'rebounds': [22, 28, 30, 31]})
df
```

## 寬表轉長表 pd.melt()

-   保留team欄位 `id_vars='team'`
-   消滅'points', 'assists', 'rebounds' `value_vars=['points', 'assists', 'rebounds']`，若為全部非id的欄位，可以省略
-   將其他欄位的名稱整合至metric欄位 `var_name='metric'`
-   數值整合至amount欄位 `value_name='amount'`

```{python}
#| echo: true
#| eval: false
pd.melt(df, id_vars='team', value_vars=['points', 'assists', 'rebounds'],
             var_name='metric', value_name='amount')
```

```{python}
#| echo: true
#| eval: false
pd.melt(df, id_vars='team',
             var_name='metric', value_name='amount')
```

## 寬表轉長表 pd.melt()

```{python}
#| echo: true
pd.melt(df, id_vars='team', value_vars=['points', 'assists', 'rebounds'],
             var_name='metric', value_name='amount')
```

## 長表轉寬表 - Recap

-   長轉寬 `資料框.pivot(index=識別欄位, columns=轉寬表欄位名稱, values=轉寬表欄位內容)`
-   寬轉長 `pd.melt(id_vars=識別欄位, value_vars=要轉成長表的欄位,var_name=新增欄位名稱, value_name=新增內容名稱)`

## Hands-on 長表轉寬表

-   直接載入[COVID-19案例數資料](https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv)
-   保留Province/State,Country/Region,Lat,Long四個欄位，將剩下的**日期欄位轉成長表**
-   請問轉換後的資料有幾列？

## 資料清洗與處理

-   Tidy Data
-   子集Subset
-   資料型態轉換處理
-   文字字串處理
-   資料組合
-   長寬表轉換
-   **遺漏值處理**

# 遺漏值處理

## 遺漏值處理

-   遺漏值(Missing Value)常常出現在真實資料內，在數值運算時常會有問題
-   最簡單的方法是將有缺值的資料移除 `.dropna()`

## 遺漏值處理 .dropna()

若資料型態為資料框，可使用`.dropna()`選出完整的資料

```{python}
#| echo: true
df_wide
```

## 遺漏值處理 .dropna()

若資料型態為資料框，可使用`.dropna()`選出完整的資料

-   axis=0: row based
-   how = 'any': 只要有na就移除

```{python}
#| echo: true
df_wide_clean=df_wide.dropna(axis = 0, how = 'any')
df_wide_clean
```

## 資料清洗與處理 - Recap

-   Tidy Data
-   子集Subset
-   資料型態轉換處理
-   文字字串處理
-   資料組合
-   長寬表轉換
-   遺漏值處理
